{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvY5cua6tQmV"
      },
      "source": [
        "###1. 기본 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wE2LwFUitERC",
        "outputId": "85f0d984-d688-4e47-d511-68d449e8a32c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.0.5)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.12/dist-packages (4.6.0)\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.12/dist-packages (1.2.8)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.12/dist-packages (0.14.0)\n",
            "Requirement already satisfied: unlzw3 in /usr/local/lib/python3.12/dist-packages (0.2.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.27.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost) (1.16.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (8.5.0)\n"
          ]
        }
      ],
      "source": [
        "#기본 환경 설정 : pandas/numpy(데이터), scikit-learn(전처리·평가·모델), xgboost/lightgbm/catboost(GBDT 계열), matplotlib(시각화).\n",
        "#추가 : imbalanced-learn : 클래스불균형 데이터 처리 기법, unlzw3 : data.Z 읽어서 해\n",
        "!pip install xgboost lightgbm catboost scikit-learn pandas numpy matplotlib imbalanced-learn unlzw3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "qoUSbFYCuDPL"
      },
      "outputs": [],
      "source": [
        "#공동 import\n",
        "import os, warnings, json  # 파일 경로 관리, 경고 무시, 설정 저장/불러오기\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import numpy as np\n",
        "import pandas as pd  # 수치계산, 데이터프레임 처리 (데이터 로딩 & EDA 기본)\n",
        "\n",
        "from pathlib import Path  # 파일/디렉토리 경로 객체형으로 다루기\n",
        "from dataclasses import dataclass  # 데이터 구조 정의 시 유용 (클래스 필드 자동 생성)\n",
        "from typing import Dict, Tuple  # 함수 타입 힌트 작성용 (Dict, Tuple 자료형 표시)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold  # 층화 교차검증 -> 클래스 비율 유지하며 K-fold split\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.compose import ColumnTransformer  # 수치형/범주형 컬럼별로 다른 전처리 적용\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler  # 범주형 변수 원-핫 인코딩 / 수치형 변수 정규화\n",
        "from sklearn.pipeline import Pipeline  # 전처리 + 모델 묶어 재현성 있게 실현\n",
        "from sklearn.metrics import (roc_auc_score, average_precision_score,\n",
        "                             f1_score, recall_score, precision_score,\n",
        "                             balanced_accuracy_score, confusion_matrix,\n",
        "                             roc_curve, precision_recall_curve, make_scorer)\n",
        "# 성능 평가지표 ROC커브 밑 면적(클래스 불균형에 강함)\n",
        "# PR 커브 기반 precision (역시 불균형 데이터 평가에 적합)\n",
        "# f1, recall, precision score : 분류 평가 지표\n",
        "# balanced accuracy score : 클래스 불균형 고려 정확도\n",
        "# confusion matrix : 예측 결과 매트릭스\n",
        "# roc_curve, precision_recall_curve : 시각화용 곡선 좌표 생성 함수\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import label_binarize\n",
        "#기존 binary class 전용 함수 (ROC-AUC, Average precision)을 멀티클래스에 쓰려면 One vs Rest(ovr) 방식으로 라벨 이진화해야 함\n",
        "#즉, 멀티클래스 평가지표 계산용\n",
        "import matplotlib.pyplot as plt  # 2D 그래프 시각화\n",
        "import seaborn as sns  # 고급 시각화 지원 (heatmap, 분포 시각화 등)\n",
        "\n",
        "from xgboost import XGBClassifier  # XGBoost 모델\n",
        "from lightgbm import LGBMClassifier  # LightGBM (빠른 boosting 모델)\n",
        "from catboost import CatBoostClassifier  # CatBoost : 범주형 변수를 자동으로 처리하는 데 강점\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "# 소수 클래스를 단순 복제하지 않고, 기존 소수 샘플을 기반으로 새로운 합성 샘플을 생성해서 오버샘플링\n",
        "# 특징 공간(feature space)에서 KNN을 이용해 인공 데이터를 만들어 학습 데이터의 클래스 균형을 맞춤\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "from scipy import sparse #전처리단계에서 OneHotEncoder를 쓰면 보통 희소행렬 (sparse matrix) 형태로 반환되는데 이를 dense array(numpy array)로 변환 위해\n",
        "from unlzw3 import unlzw #압축 풀기\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    f1_score, balanced_accuracy_score, confusion_matrix,\n",
        "    roc_auc_score, average_precision_score, make_scorer\n",
        ")\n",
        "from scipy.stats import randint, uniform, loguniform  # 튜닝용 분포"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciqA_VwxvSWZ",
        "outputId": "85df08d7-5a0f-4455-b578-773de5021f29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') #드라이브에서 마운트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8UJL70zvTGx",
        "outputId": "55c87735-1ff3-41c1-8e63-8212579c384d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "프로젝트 폴더: /content/drive/MyDrive/imbalanced_loss_project\n",
            "데이터 폴더: /content/drive/MyDrive/imbalanced_loss_project/data\n",
            "결과 폴더: /content/drive/MyDrive/imbalanced_loss_project/results\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "RANDOM_STATE = 42 #랜덤시드 고정 값\n",
        "N_SPLITS = 5 #교차검증 시 데이터셋 몇 조각으로 나눌\n",
        "\n",
        "# 프로젝트 폴더 지정 (구글 드라이브 안의 프로젝트 루트 경로를 고정)\n",
        "# 이후 모든 데이터, 소스, 결과 파일 경로를 이 경로 기준으로 관리\n",
        "project_dir = \"/content/drive/MyDrive/imbalanced_loss_project\"\n",
        "\n",
        "# 하위 폴더 정의 (데이터/소스코드/결과 저장용 디렉토리)\n",
        "# → 프로젝트 구조를 체계적으로 관리하기 위함\n",
        "data_dir    = os.path.join(project_dir, \"data\")     # 데이터셋 저장 위치\n",
        "src_dir     = os.path.join(project_dir, \"src\")      # 사용자 정의 모듈/소스코드 저장 위치\n",
        "results_dir = os.path.join(project_dir, \"results\")  # 실험 결과(모델 성능, 그래프 등) 저장 위치\n",
        "os.makedirs(results_dir, exist_ok=True) #결과 저장용 폴더 자동 생성\n",
        "\n",
        "# src 폴더를 Python 모듈 검색 경로에 추가\n",
        "# src 안의 custom_losses.py, evaluation.py 같은 사용자 정의 모듈을 import 가능하게 함\n",
        "if src_dir not in sys.path:\n",
        "    sys.path.append(src_dir)\n",
        "\n",
        "#확인\n",
        "print(\"프로젝트 폴더:\", project_dir)\n",
        "print(\"데이터 폴더:\", data_dir)\n",
        "print(\"결과 폴더:\", results_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "bCIs0zKGv1vP"
      },
      "outputs": [],
      "source": [
        "#데이터프레임 df에서 숫자형 컬럼과 범주형 컬럼 분리\n",
        "def split_features(df: pd.DataFrame):\n",
        "    num = df.select_dtypes(include=[np.number]).columns.tolist() #수치형 변수\n",
        "    cat = [c for c in df.columns if c not in num] #수치형 외 컬럼 목록\n",
        "    return num, cat\n",
        "\n",
        "#결측치 비율이 60% 이상인 컬럼은 삭제\n",
        "def make_preprocessor(X: pd.DataFrame, high_na_drop=0.60):\n",
        "    keep = X.columns[X.isna().mean() <= high_na_drop]\n",
        "    X2 = X[keep].copy()\n",
        "    num_cols, cat_cols = split_features(X2)\n",
        "    num_pipe = Pipeline([ #숫자형 컬럼(결측치 median으로 채우고 N(0,1)로 표준화)\n",
        "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "        (\"scaler\", StandardScaler())\n",
        "    ])\n",
        "    cat_pipe = Pipeline([ #범주형 컬럼(결측치 최빈값으로 채우고 onehotencoder)\n",
        "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "    ])\n",
        "    pre = ColumnTransformer([ #숫자,번주형 파이프라인 묶어서 한 번에 전처리하기\n",
        "        (\"num\", num_pipe, num_cols),\n",
        "        (\"cat\", cat_pipe, cat_cols)\n",
        "    ], remainder=\"drop\")\n",
        "    return pre, X2\n",
        "\n",
        "#클래스별 샘플 개수 입력 받아 클래스 가중치 계산\n",
        "def adaptive_class_weights_from_counts(class_counts: np.ndarray):\n",
        "    n = class_counts.astype(float)\n",
        "    w = 1.0 / np.log(1.0 + n) #1/log(1+n) 사용해 극단적으로 커지는 것 방지\n",
        "    w[~np.isfinite(w)] = 0.0\n",
        "    return w\n",
        "\n",
        "def make_sample_weights(y: pd.Series | np.ndarray): #실제 라벨 벡터 받아서 클래스별 개수(counts) 구하고 클래스별 가중치 구함\n",
        "    y = np.asarray(y)\n",
        "    classes, counts = np.unique(y, return_counts=True)\n",
        "    w = adaptive_class_weights_from_counts(counts)\n",
        "    class_to_w = {c: w_i for c, w_i in zip(classes, w)}\n",
        "    sw = np.vectorize(class_to_w.get)(y).astype(float)\n",
        "    return sw, class_to_w\n",
        "\n",
        "def _to_dense(Xm): #sparse면 dense\n",
        "    return Xm.toarray() if sparse.issparse(Xm) else Xm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "4hIbACp64xnq"
      },
      "outputs": [],
      "source": [
        "#데이터 로더\n",
        "def _read_pageblocks(data_dir: str):\n",
        "    # 우선 page-blocks.data가 있으면 그대로 읽기 아니면 압축버전 읽기\n",
        "    path_plain = os.path.join(data_dir, \"page-blocks.data\")\n",
        "    path_Z     = os.path.join(data_dir, \"page-blocks.data.Z\")\n",
        "    if os.path.exists(path_plain):\n",
        "        df = pd.read_csv(path_plain, header=None, delim_whitespace=True)\n",
        "    elif os.path.exists(path_Z):\n",
        "        # .Z를 메모리에서 해제하여 파싱 (unlzw3 라이브러리로 해제한 뒤 pandas로 읽음)\n",
        "        with open(path_Z, \"rb\") as f:\n",
        "            raw = f.read()\n",
        "        decompressed = unlzw(raw)\n",
        "        from io import BytesIO\n",
        "        df = pd.read_csv(BytesIO(decompressed), header=None, delim_whitespace=True)\n",
        "    else:\n",
        "        raise FileNotFoundError(\"page-blocks.data(.Z) 파일을 찾을 수 없습니다.\")\n",
        "    return df\n",
        "\n",
        "def _read_covtype(data_dir: str):\n",
        "    # covtype.data.gz\n",
        "    path = os.path.join(data_dir, \"covtype.data.gz\")\n",
        "    df = pd.read_csv(path, header=None)\n",
        "    return df\n",
        "\n",
        "def _read_glass(data_dir: str):\n",
        "    # glass.data\n",
        "    path = os.path.join(data_dir, \"glass.data\")\n",
        "    if not os.path.exists(path):\n",
        "        path = os.path.join(data_dir, \"glass.data.txt\")  # 혹시 이름이 다르면 대비\n",
        "    df = pd.read_csv(path, header=None, sep=r\"[,\\s]+\", engine=\"python\") #sep 써서 공백, 쉼표 둘 다 구분자로 사용\n",
        "    return df\n",
        "\n",
        "def _read_faults(data_dir: str):\n",
        "    # Faults.NNA\n",
        "    path = os.path.join(data_dir, \"Faults.NNA\")\n",
        "    df = pd.read_csv(path, header=None, delim_whitespace=True)\n",
        "    return df\n",
        "\n",
        "def _read_yeast(data_dir: str):\n",
        "    # yeast.data\n",
        "    path = os.path.join(data_dir, \"yeast.data\")\n",
        "    df = pd.read_csv(path, header=None, delim_whitespace=True)\n",
        "    return df\n",
        "\n",
        "def _standardize_feature_names(X: pd.DataFrame):\n",
        "    #컬럼명이 정수일 때 ColumnTransformer가 위치 인덱스로 오해하는 문제 방지\n",
        "    X = X.copy()\n",
        "    X.columns = [f\"f{i}\" for i in range(X.shape[1])]\n",
        "    return X\n",
        "\n",
        "def load_dataset(dataset_name: str, base_data_path: str, random_state=42):\n",
        "    ds = dataset_name.lower()\n",
        "    if ds == \"covertype\":\n",
        "        df = _read_covtype(base_data_path)\n",
        "        X = df.iloc[:, :-1].copy()\n",
        "        y = df.iloc[:, -1].astype(int).values  # 1..7\n",
        "        y = y - 1  # 0..6 로 정규화 (gpt 권장)\n",
        "        X = _standardize_feature_names(X)\n",
        "\n",
        "    elif ds == \"glass\":\n",
        "        df = _read_glass(base_data_path)\n",
        "        # 일반적으로 첫 컬럼이 ID, 마지막이 라벨\n",
        "        X = df.iloc[:, 1:-1].copy()\n",
        "        y = df.iloc[:, -1].astype(int).values\n",
        "        # 라벨이 1,2,3,5,6,7 등 불연속일 수 있으므로 0..K-1로 인코딩\n",
        "        le = LabelEncoder()\n",
        "        y = le.fit_transform(y)\n",
        "        X = _standardize_feature_names(X)\n",
        "\n",
        "    elif ds == \"page_blocks\" or ds == \"page-blocks\":\n",
        "        df = _read_pageblocks(base_data_path)\n",
        "        # 마지막 컬럼이 라벨(1..5)\n",
        "        X = df.iloc[:, :-1].copy()\n",
        "        y = df.iloc[:, -1].astype(int).values\n",
        "        y = y - 1\n",
        "        X = _standardize_feature_names(X)\n",
        "\n",
        "    elif ds in (\"steel_plates_faults\", \"steel plates faults\", \"steel\"):\n",
        "        df = _read_faults(base_data_path)\n",
        "        # 문헌상 마지막 7개 컬럼이 결함(one-hot) -> 단일 라벨로 변환\n",
        "        # (총 컬럼 수가 다를 수 있으니 뒤에서 7개를 라벨로 가정)\n",
        "        K = 7\n",
        "        X = df.iloc[:, :-K].copy()\n",
        "        Y_onehot = df.iloc[:, -K:].values\n",
        "        y = Y_onehot.argmax(axis=1)\n",
        "        X = _standardize_feature_names(X)\n",
        "\n",
        "    elif ds == \"yeast\":\n",
        "        df = _read_yeast(base_data_path)\n",
        "        # 0:name, 1..8: features(8개), 9: class(str)\n",
        "        X = df.iloc[:, 1:-1].astype(float).copy()\n",
        "        y_raw = df.iloc[:, -1].astype(str).values\n",
        "        le = LabelEncoder()\n",
        "        y = le.fit_transform(y_raw)  # 0..K-1\n",
        "        X = _standardize_feature_names(X)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"지원되지 않는 멀티클래스 데이터셋: {dataset_name}\")\n",
        "\n",
        "    return train_test_split(X, y, test_size=0.2, random_state=random_state, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "YQERBlnV-cSW"
      },
      "outputs": [],
      "source": [
        "# 모델 플랜(데이터 특성에 맞춰 대충 좋은 기본값)\n",
        "MODEL_PLAN = {\n",
        "    \"covertype\":       \"lightgbm\",   # 큰 표본 + 수치형 위주 -> LGBM 쾌적\n",
        "    \"glass\":           \"xgboost\",    # 소표본, 경계 복잡 -> XGB 시도\n",
        "    \"page_blocks\":     \"lightgbm\",   # 표본 큼 -> LGBM\n",
        "    \"steel_plates_faults\": \"xgboost\",\n",
        "    \"yeast\":           \"catboost\",   # 클래스 불균형 + 비선형성 -> CatBoost도 괜찮음\n",
        "}\n",
        "\n",
        "LOSS_STRATEGIES = [\"baseline\", \"adaptive_ce\", \"weighted\", \"smote\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "5Gn6FBVj-ivt"
      },
      "outputs": [],
      "source": [
        "#멀티클래스에서 클래스별 recall 계산해 기하평균으로 묶기\n",
        "def gmean_recall_multiclass(y_true, y_pred, labels=None):\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "    # 클래스별 recall = TP_i / (TP_i + FN_i)\n",
        "    recalls = []\n",
        "    for i in range(cm.shape[0]):\n",
        "        tp = cm[i, i]\n",
        "        fn = cm[i, :].sum() - tp\n",
        "        rec = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "        recalls.append(rec)\n",
        "    # 기하평균 -> 어느 한 클래스의 recall이 0에 가까우면 전체 점수가 크게 깎임 (소수 클래스 민감)\n",
        "    # 단 한 클래스라도 분모가 0이면 (샘플 없음) 0 처리 되어 전체가 0이 될 수 있\n",
        "    recalls = np.array(recalls, dtype=float)\n",
        "    # 0이 있으면 전체가 0이 되므로, 아주 작은 epsilon 더하는 방법도 있으나 그대로 둠\n",
        "    return float(np.prod(recalls) ** (1.0 / max(len(recalls), 1)))\n",
        "\n",
        "def evaluate_multiclass_model(\n",
        "    y_true, proba, model_name: str, loss_name: str, dataset_name: str\n",
        "):\n",
        "\n",
        "    # 멀티클래스 성능 종합 평가.\n",
        "    # 입력: y_true(정수 레이블), proba((n_samples, K) 확률)\n",
        "    # 출력: metrics(dict)\n",
        "\n",
        "    # 예측 라벨\n",
        "    y_pred = proba.argmax(axis=1)\n",
        "    classes = np.unique(y_true)\n",
        "\n",
        "    # 기본 지표\n",
        "    metrics = {\n",
        "        \"dataset\": dataset_name,\n",
        "        \"model\": model_name,\n",
        "        \"loss\": loss_name,\n",
        "        \"f1_macro\": f1_score(y_true, y_pred, average=\"macro\"),\n",
        "        \"f1_weighted\": f1_score(y_true, y_pred, average=\"weighted\"),\n",
        "        \"bal_acc\": balanced_accuracy_score(y_true, y_pred),\n",
        "        \"gmean\": gmean_recall_multiclass(y_true, y_pred, labels=classes),\n",
        "    }\n",
        "\n",
        "    # 확률 기반 지표 (OvR, macro) — 실패 시 NaN\n",
        "    # macro : 멀티클래스 → One-vs-Rest 변환 → 클래스별 accuracy → 매크로 평균\n",
        "    # 각 클래스에 동등한 가중치를 주기 때문에, 소수 클래스 성능도 잘 반영된다.\n",
        "    try:\n",
        "        metrics[\"roc_auc_macro_ovr\"] = roc_auc_score(\n",
        "            y_true, proba, multi_class=\"ovr\", average=\"macro\"\n",
        "        )\n",
        "    except Exception:\n",
        "        metrics[\"roc_auc_macro_ovr\"] = np.nan\n",
        "\n",
        "    try:\n",
        "        Y_bin = label_binarize(y_true, classes=classes)  # (n, K) 이진 행렬\n",
        "        metrics[\"avg_precision_macro_ovr\"] = average_precision_score(\n",
        "            Y_bin, proba, average=\"macro\"\n",
        "        )\n",
        "    except Exception:\n",
        "        metrics[\"avg_precision_macro_ovr\"] = np.nan\n",
        "\n",
        "    # 로그 출력\n",
        "    print(f\"[{dataset_name} | {model_name}-{loss_name}] {metrics}\")\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#튜닝\n",
        "f1_macro_scorer = make_scorer(f1_score, average=\"macro\")\n",
        "cv5 = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
        "\n",
        "def get_model_and_space(model_tag, K):\n",
        "    if model_tag == \"xgboost\":\n",
        "        model = XGBClassifier(objective=\"multi:softprob\", num_class=K, tree_method=\"hist\",\n",
        "                              eval_metric=\"mlogloss\", random_state=RANDOM_STATE)\n",
        "        space = {\n",
        "            \"n_estimators\": randint(300, 1201),\n",
        "            \"learning_rate\": loguniform(1e-2, 3e-1),\n",
        "            \"max_depth\": randint(3, 11),\n",
        "            \"min_child_weight\": randint(1, 11),\n",
        "            \"subsample\": uniform(0.6, 0.4),\n",
        "            \"colsample_bytree\": uniform(0.6, 0.4),\n",
        "            \"reg_lambda\": loguniform(1e-3, 10),\n",
        "        }\n",
        "    elif model_tag == \"lightgbm\":\n",
        "        model = LGBMClassifier(objective=\"multiclass\", num_class=K, random_state=RANDOM_STATE)\n",
        "        space = {\n",
        "            \"n_estimators\": randint(300, 1201),\n",
        "            \"learning_rate\": loguniform(1e-2, 2e-1),\n",
        "            \"num_leaves\": randint(31, 257),\n",
        "            \"max_depth\": randint(4, 13),\n",
        "            \"min_child_samples\": randint(10, 201),\n",
        "            \"subsample\": uniform(0.6, 0.4),\n",
        "            \"colsample_bytree\": uniform(0.6, 0.4),\n",
        "            \"reg_lambda\": loguniform(1e-3, 10),\n",
        "        }\n",
        "    elif model_tag == \"catboost\":\n",
        "        model = CatBoostClassifier(loss_function=\"MultiClass\", random_state=RANDOM_STATE, verbose=False)\n",
        "        space = {\n",
        "            \"iterations\": randint(300, 1201),\n",
        "            \"learning_rate\": loguniform(1e-2, 2e-1),\n",
        "            \"depth\": randint(4, 11),\n",
        "            \"l2_leaf_reg\": loguniform(1e-2, 10),\n",
        "            \"bagging_temperature\": uniform(0.0, 1.0),\n",
        "        }\n",
        "    else:\n",
        "        raise ValueError(\"지원되지 않는 모델 태그\")\n",
        "    return model, space\n",
        "\n",
        "def DO_TUNE(model, param_dist, X_train, y_train, cv_splits=3, n_iter=20, random_state=42):\n",
        "\n",
        "    #주어진 모델과 파라미터 분포에 대해 RandomizedSearchCV를 실행해 최적 모델을 리턴\n",
        "\n",
        "    scorer = make_scorer(f1_score, average=\"macro\")\n",
        "    cv = StratifiedKFold(n_splits=cv_splits, shuffle=True, random_state=random_state)\n",
        "\n",
        "    search = RandomizedSearchCV(\n",
        "        estimator=model,\n",
        "        param_distributions=param_dist,\n",
        "        n_iter=n_iter,\n",
        "        scoring=scorer,\n",
        "        cv=cv,\n",
        "        verbose=1,\n",
        "        n_jobs=-1,\n",
        "        random_state=random_state\n",
        "    )\n",
        "    search.fit(X_train, y_train)\n",
        "\n",
        "    print(\"Best Params:\", search.best_params_)\n",
        "    print(\"Best Score :\", search.best_score_)\n",
        "\n",
        "    return search.best_estimator_\n",
        "\n",
        "def tune_once(model_tag, K, X, y, strategy=\"baseline\", n_iter=25):\n",
        "    base_model, space = get_model_and_space(model_tag, K)\n",
        "    if strategy == \"smote\":\n",
        "        pipe = ImbPipeline([\n",
        "            (\"smote\", SMOTE(random_state=RANDOM_STATE, sampling_strategy=\"not majority\", k_neighbors=5)),\n",
        "            (\"clf\", base_model),\n",
        "        ])\n",
        "        param_dist = {f\"clf__{k}\": v for k, v in space.items()}\n",
        "        search = RandomizedSearchCV(pipe, param_distributions=param_dist, n_iter=n_iter,\n",
        "                                    scoring=f1_macro_scorer, cv=cv5, n_jobs=-1, verbose=1,\n",
        "                                    random_state=RANDOM_STATE)\n",
        "    else:\n",
        "        search = RandomizedSearchCV(base_model, param_distributions=space, n_iter=n_iter,\n",
        "                                    scoring=f1_macro_scorer, cv=cv5, n_jobs=-1, verbose=1,\n",
        "                                    random_state=RANDOM_STATE)\n",
        "    search.fit(X, y)\n",
        "    return search.best_estimator_, search.best_params_, search.best_score_"
      ],
      "metadata": {
        "id": "oL3R2ai55GBg"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYA0q8ej-m4c"
      },
      "source": [
        "### 2. 실행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "16z2bWTqBAor",
        "outputId": "117e78ae-5b99-4880-f069-155c9f0d7b02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========================= COVERTYPE =========================\n",
            "Train shape: (464809, 54), Test shape: (116203, 54)\n",
            "Class dist (train): {0: 0.3646056767403385, 1: 0.48759813170571137, 2: 0.06153710448808005, 3: 0.004728824097640106, 4: 0.01633789362942628, 5: 0.029891848049413847, 6: 0.03530052128938983}\n"
          ]
        }
      ],
      "source": [
        "# 실행할 데이터셋\n",
        "TARGET_DATASETS = [\n",
        "    \"covertype\",\n",
        "    \"glass\",\n",
        "    \"page_blocks\",\n",
        "    \"steel_plates_faults\",\n",
        "    \"yeast\",\n",
        "]\n",
        "\n",
        "all_results = []\n",
        "\n",
        "for dataset_name in TARGET_DATASETS:\n",
        "    print(f\"\\n{'='*25} {dataset_name.upper()} {'='*25}\")\n",
        "    X_train, X_test, y_train, y_test = load_dataset(dataset_name, data_dir, random_state=RANDOM_STATE)\n",
        "    print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n",
        "    uniq, cnts = np.unique(y_train, return_counts=True)\n",
        "    print(\"Class dist (train):\", {int(k): float((v/len(y_train))) for k, v in zip(uniq, cnts)})\n",
        "\n",
        "    # 전처리\n",
        "    pre, _ = make_preprocessor(X_train, high_na_drop=0.60)\n",
        "    Xtr_t = _to_dense(pre.fit_transform(X_train))\n",
        "    Xte_t = _to_dense(pre.transform(X_test))\n",
        "\n",
        "    K = len(np.unique(y_train))\n",
        "    model_tag = MODEL_PLAN[dataset_name]\n",
        "\n",
        "    for strategy in LOSS_STRATEGIES:\n",
        "        print(f\"\\n Training | model={model_tag}, strategy={strategy}\")\n",
        "\n",
        "        X_fit, y_fit = Xtr_t, y_train.copy()\n",
        "        fit_kwargs = {}\n",
        "\n",
        "        if strategy == \"smote\":\n",
        "            # 공백! \"not majority\" (언더스코어 X)\n",
        "            sm = SMOTE(random_state=RANDOM_STATE, sampling_strategy=\"not majority\", k_neighbors=5)\n",
        "            X_fit, y_fit = sm.fit_resample(Xtr_t, y_train)\n",
        "\n",
        "        elif strategy == \"adaptive_ce\":\n",
        "            sw, class_to_w = make_sample_weights(y_fit)\n",
        "            fit_kwargs[\"sample_weight\"] = sw\n",
        "            print(\"adaptive weights:\", class_to_w)\n",
        "\n",
        "        elif strategy == \"weighted\":\n",
        "            classes_, counts_ = np.unique(y_fit, return_counts=True)\n",
        "            w_inv = 1.0 / counts_\n",
        "            class_to_w = {c: w for c, w in zip(classes_, w_inv)}\n",
        "            sw = np.vectorize(class_to_w.get)(y_fit)\n",
        "            fit_kwargs[\"sample_weight\"] = sw\n",
        "            print(\"weighted(inv-freq) weights:\", class_to_w)\n",
        "\n",
        "        # 모델\n",
        "        if model_tag == \"xgboost\":\n",
        "            model = XGBClassifier(objective=\"multi:softprob\", num_class=K, n_estimators=600,\n",
        "                                  learning_rate=0.05, max_depth=6, subsample=0.8, colsample_bytree=0.8,\n",
        "                                  tree_method=\"hist\", eval_metric=\"mlogloss\", random_state=RANDOM_STATE)\n",
        "        elif model_tag == \"lightgbm\":\n",
        "            model = LGBMClassifier(objective=\"multiclass\", num_class=K, n_estimators=500,\n",
        "                                   learning_rate=0.05, num_leaves=64, subsample=0.8, colsample_bytree=0.8,\n",
        "                                   random_state=RANDOM_STATE)\n",
        "        elif model_tag == \"catboost\":\n",
        "            model = CatBoostClassifier(loss_function=\"MultiClass\", iterations=700, depth=6,\n",
        "                                       learning_rate=0.05, random_state=RANDOM_STATE, verbose=False)\n",
        "        else:\n",
        "            raise ValueError(f\"지원되지 않는 모델: {model_tag}\")\n",
        "\n",
        "        # 튜닝(옵션)\n",
        "        if DO_TUNE:\n",
        "            tuned_model, best_params, cv_score = tune_once(model_tag, K, X_fit, y_fit, strategy=strategy, n_iter=25)\n",
        "            print(\"Best params:\", best_params, \"| CV f1_macro:\", f\"{cv_score:.4f}\")\n",
        "            model = tuned_model\n",
        "\n",
        "        # 학습\n",
        "        model.fit(X_fit, y_fit, **fit_kwargs)\n",
        "\n",
        "        # 예측 확률 (n,K)\n",
        "        proba = model.predict_proba(Xte_t)\n",
        "        if isinstance(proba, list):  # CatBoost 방어\n",
        "            proba = np.asarray(proba)\n",
        "            if proba.ndim == 3:  # (K, n, 2) 등 예외형태 방어\n",
        "                proba = np.transpose(proba, (1, 0, 2))[:, :, 1]\n",
        "            elif proba.ndim == 2:\n",
        "                pass\n",
        "\n",
        "        # 평가\n",
        "        metrics = evaluate_multiclass_model(\n",
        "            y_true=y_test,\n",
        "            proba=proba,\n",
        "            model_name=f\"{model_tag}-{strategy}\",\n",
        "            loss_name=(\"adaptive_ce\" if strategy == \"adaptive_ce\" else strategy),\n",
        "            dataset_name=dataset_name\n",
        "        )\n",
        "        all_results.append(metrics)\n",
        "\n",
        "# 요약 저장\n",
        "results_df = pd.DataFrame(all_results)\n",
        "results_df.sort_values([\"dataset\", \"f1_macro\"], ascending=[True, False], inplace=True)\n",
        "results_csv = os.path.join(results_dir, \"multiclass_summary.csv\")\n",
        "results_df.to_csv(results_csv, index=False)\n",
        "print(\"\\nSaved:\", results_csv)\n",
        "display(results_df.head(20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEhVgJdTBPwg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}